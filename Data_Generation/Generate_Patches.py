#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# %%
"""
Created on Wed Jun 29 09:59:33 2022
Patch Generation code.. works for all cohorts: TCGA, IMM150, UTSW
Generates patches from a Slide and a mask..
Assumes all slides are either 20X or 40X and also Patches are generated at 20X
@author: s186208
"""
import yaml
import os as os

import sys

parent_dir = os.path.dirname(os.path.dirname(__file__))
print(parent_dir)
sys.path.insert(0, parent_dir)

import Data_Generation.PatchGen as pg
import openslide as oSlide

import argparse
import ImageUtils as iu
import glob
import pandas as pd
import numpy as np

import multiprocessing as mp
import pickle

#%%
def parse_args():                                                                                                                                     
    """Parse input arguments.                                                                                                                         
    Parameters                                                                                                                                        
    -------------------                                                                                                                               
    No parameters.                                                                                                                                    
    Returns                                                                                                                                           
    -------------------                                                                                                                               
    args: argparser.Namespace class object                                                                                                            
        An argparse.Namespace class object contains experimental hyper-parameters.                                                                    
    """                                                                                                                                               
    parser = argparse.ArgumentParser(description='Automated job submission')                                                                          
                                                                                                                                                      
                                                                                                                                                      
    parser.add_argument('--yamlFile', dest='yamlFile',type=str)

    args = parser.parse_args()
    return args

args=parse_args()


#%% read Yaml Data

yamlFileName=args.yamlFile
   
assert os.path.isfile(yamlFileName), f"File '{yamlFileName}' does not exist"
                                                                  
with open(yamlFileName) as file:                                                                                      
    yamlData = yaml.load(file, Loader=yaml.FullLoader)                                                                    
print(yamlData)



#%%
# this is case specific code to extract two seperate groups of files:
# masks are manually annotated, and masks are generated by tumor classifier..
# additional code for eliminating any files is also incorporated here
# files are balck-listed as per pathologist
def get_file_list(yamlData):
    if yamlData['dataType'] == 'TCGA':

        trainFoldsIdx,testFoldsIdx=pickle.load(open(yamlData['foldsSaveFile'],'rb'))
        # get finalds as a concatenated .. 
        finalIds=np.concatenate((trainFoldsIdx[0], testFoldsIdx[0]))
        # note these are zero-based index..
        finalIds=finalIds+1
        # masks with manual annotations        
        annoFiles=[os.path.split(f)[-1] for f in glob.glob(os.path.join(yamlData['annoDir'],'*.txt'))]
        svsList=[name.replace('.txt','.svs') for name in annoFiles]
        
        annoIds=[]
        for name in svsList:
            val=name.split('_')[2].split('.')[0]
            annoIds.append(int(val))
        # confirm annoIds are in finalIds
 
        finalAnnoIds=[idval for idval in annoIds if idval in finalIds]
        # find ids from tumor masks..
        finaltumorIds=[idval for idval in finalIds if idval not in annoIds]
    
        annoSvsList=['TCGA_FFPE_'+str(idval).zfill(3)+'.svs' for idval in finalAnnoIds]
        tumorSvsList=['TCGA_FFPE_'+str(idval).zfill(3)+'.svs' for idval in finaltumorIds]
        annoFileList=[nameVal.replace('svs','txt') for nameVal in annoSvsList]
        annoFileFpList=[os.path.join(yamlData['annoDir'], fileName) for fileName in annoFileList]
        annoSvsFpList=[os.path.join(yamlData['svsDir'], fileName) for fileName in annoSvsList]
        tumorSvsFpList=[os.path.join(yamlData['svsDir'], fileName) for fileName in tumorSvsList]
        tumorMaskList=[nameVal.replace('svs','pkl') for nameVal in tumorSvsList]
        tumorMaskFpList=[os.path.join(yamlData['tumorMaskDir'],nameVal) for nameVal in tumorMaskList]
        for fileName in annoFileFpList:
            assert os.path.exists(fileName)
        for fileName in annoSvsFpList:
            assert os.path.exists(fileName)    
        for fileName in tumorSvsFpList:
            assert os.path.exists(fileName)
        for fileName in tumorMaskFpList:
            assert os.path.exists(fileName)
            
    elif yamlData['dataType'] == 'IMM150':

        excludeList=yamlData['excludeList']
        duplicateList=yamlData['duplicateList']
        removeList=excludeList+duplicateList
        allFiles=[os.path.split(f)[-1] for f in glob.glob(os.path.join(yamlData['svsDir'],'*.ndpi'))]
        netFiles=[name for name in allFiles if name not in removeList]
        # find all annoFiles
        annoFiles=[os.path.split(f)[-1] for f in glob.glob(os.path.join(yamlData['annoDir'],'*.txt'))]
        annoSvsList=[name.replace('.txt','.ndpi') for name in annoFiles]
        # find only annoFiles that are needed (.ie. remove any files that are in removeList)
        netAnnoSvsList=[name for name in annoSvsList if name not in removeList]
        netAnnoList=[name.replace('.ndpi','.txt') for name in netAnnoSvsList]
        tumorSvsList=[name for name in netFiles if name not in netAnnoSvsList]
        # now find full path list
        annoFileFpList=[os.path.join(yamlData['annoDir'], name) for name in netAnnoList]
        annoSvsFpList=[os.path.join(yamlData['svsDir'], fileName) for fileName in netAnnoSvsList]
        tumorSvsFpList=[os.path.join(yamlData['svsDir'], fileName) for fileName in tumorSvsList]
        tumorMaskList=[nameVal.replace('ndpi','pkl') for nameVal in tumorSvsList]
        tumorMaskFpList=[os.path.join(yamlData['tumorMaskDir'],nameVal) for nameVal in tumorMaskList]
        print('Number of tumor masks:', len(tumorSvsList))
        print('Number of annotated masks:', len(netAnnoSvsList))
        print('Total number of Files:', len(netFiles))

        for fileName in annoFileFpList:
            assert os.path.exists(fileName)
        for fileName in annoSvsFpList:
            assert os.path.exists(fileName)    
        for fileName in tumorSvsFpList:
            assert os.path.exists(fileName)
        for fileName in tumorMaskFpList:
            assert os.path.exists(fileName)
            
    elif yamlData['dataType'] == 'IMM150_B2':
        

        excludeList= yamlData['excludeList']
        removeList=excludeList
        allFiles=[os.path.split(f)[-1] for f in glob.glob(os.path.join(yamlData['svsDir'],'*.ndpi'))]
        netFiles=[name for name in allFiles if name not in removeList]
        # find all annoFiles
        annoFiles=[os.path.split(f)[-1] for f in glob.glob(os.path.join(yamlData['annoDir'],'*.txt'))]
        annoSvsList=[name.replace('.txt','.ndpi') for name in annoFiles]
        # find only annoFiles that are needed (.ie. remove any files that are in removeList)
        netAnnoSvsList=[name for name in annoSvsList if name not in removeList]
        netAnnoList=[name.replace('.ndpi','.txt') for name in netAnnoSvsList]
        tumorSvsList=[name for name in netFiles if name not in netAnnoSvsList]
        # now find full path list
        annoFileFpList=[os.path.join(yamlData['annoDir'], name) for name in netAnnoList]
        annoSvsFpList=[os.path.join(yamlData['svsDir'], fileName) for fileName in netAnnoSvsList]
        tumorSvsFpList=[os.path.join(yamlData['svsDir'], fileName) for fileName in tumorSvsList]
        tumorMaskList=[nameVal.replace('ndpi','pkl') for nameVal in tumorSvsList]
        tumorMaskFpList=[os.path.join(yamlData['tumorMaskDir'],nameVal) for nameVal in tumorMaskList]
        print('Number of tumor masks:', len(tumorSvsList))
        print('Number of annotated masks:', len(netAnnoSvsList))
        print('Total number of Files:', len(netFiles))

        for fileName in annoFileFpList:
            assert os.path.exists(fileName)
        for fileName in annoSvsFpList:
            assert os.path.exists(fileName)    
        for fileName in tumorSvsFpList:
            assert os.path.exists(fileName)
        for fileName in tumorMaskFpList:
            assert os.path.exists(fileName)
            
    elif yamlData['dataType'] == 'UTSW':
        
        excludeList= yamlData['excludeList']
        project=yamlData['dataType']
        idMappingFile=yamlData['mappingFile']
        projectToSheet={'UTSW':'internal','External':'external'}
        idMapping=pd.read_excel(idMappingFile,sheet_name=projectToSheet[project]).set_index('SVS')
        idMapping = idMapping.drop(excludeList)
        allSvsList=idMapping.index.to_list()
        annoFileFpList=glob.glob(os.path.join(yamlData['annoDir'],'*.txt'))
        annoSvsList=[os.path.split(name)[-1].replace('.txt','.svs') for  name in annoFileFpList]
        tumorSvsList=[name for name in allSvsList if name not in annoSvsList]
        annoSvsFpList=[os.path.join(yamlData['svsDir'],name) for name in annoSvsList]
        tumorSvsFpList=[os.path.join(yamlData['svsDir'],name) for name in tumorSvsList]
        tumorMaskList=[name.replace('svs','pkl') for name in tumorSvsList]
        tumorMaskFpList=[os.path.join(yamlData['tumorMaskDir'],name) for name in tumorMaskList]
        print('Number of tumor masks:', len(tumorSvsList))
        print('Number of annotated masks:', len(annoSvsList))
        print('Total number of Files:', len(allSvsList))
        for fileName in annoFileFpList:
            assert os.path.exists(fileName)
        for fileName in annoSvsFpList:
            assert os.path.exists(fileName)    
        for fileName in tumorSvsFpList:
            assert os.path.exists(fileName)
        for fileName in tumorMaskFpList:
            assert os.path.exists(fileName)
            
            
    elif yamlData['dataType'] == 'EXTERNAL':
        excludeList=yamlData['excludeList']
        project='External'
        idMappingFile=yamlData['mappingFile']
        projectToSheet={'UTSW':'internal','External':'external'}
        idMapping=pd.read_excel(idMappingFile,sheet_name=projectToSheet[project]).set_index('SVS')
        idMapping = idMapping.drop(excludeList)
        allSvsList=idMapping.index.to_list()
        annoFileFpList=glob.glob(os.path.join(yamlData['annoDir'],'*.txt'))
        annoSvsList=[os.path.split(name)[-1].replace('.txt','.svs') for  name in annoFileFpList]
        tumorSvsList=[name for name in allSvsList if name not in annoSvsList]
        annoSvsFpList=[os.path.join(yamlData['svsDir'],name) for name in annoSvsList]
        tumorSvsFpList=[os.path.join(yamlData['svsDir'],name) for name in tumorSvsList]
        tumorMaskList=[name.replace('svs','pkl') for name in tumorSvsList]
        tumorMaskFpList=[os.path.join(yamlData['tumorMaskDir'],name) for name in tumorMaskList]
        print('Number of tumor masks:', len(tumorSvsList))
        print('Number of annotated masks:', len(annoSvsList))
        print('Total number of Files:', len(allSvsList))
        for fileName in annoFileFpList:
            assert os.path.exists(fileName)
        for fileName in annoSvsFpList:
            assert os.path.exists(fileName)    
        for fileName in tumorSvsFpList:
            assert os.path.exists(fileName)
        for fileName in tumorMaskFpList:
            assert os.path.exists(fileName)
        
    return annoFileFpList,annoSvsFpList,tumorSvsFpList,tumorMaskFpList


#%%
def GeneratePatchesFromAnnotations(annoList,annoSvsList,yamlData):
    patchSize=yamlData['patchSize']
    distinguishAnnosInClass=False # IF False, all annotations of the same class are treated as one
    patchSizeList=[patchSize]
    showProgress=False
    maxPatchesPerAnno=1500 # Maximum number of patches sampled from an annotation
    maxAvgPatchOverlap=8.0 # How tightly patches are allowed to overlap. 0 implies no overlap, 1 implies number of patches is selected so that combined area of patches= area of annotation
    minFracPatchInAnno=0.90 # What percentage of the patch must belong to same class as the center pixel, for the patch to be considered
    layerName='Tumor' 
    maskDsf=1  # ie mask is same size as slide both at 40X see definition copied from below
    #   downSampleFactor    - scalar dnoting how may fold smaller the mask is than the slide.                                
    patchSaveDir=yamlData['patchSaveDir']
    for index, svsFile in enumerate(annoSvsList):
        print('working on svs:', svsFile )
        annoFile=annoList[index]
        hdf5File=os.path.join(patchSaveDir, os.path.split(annoFile)[-1].replace('.txt','.hdf5'))
        if not os.path.exists(hdf5File):
            slide=oSlide.open_slide(svsFile)
            slideMpp = np.mean([float(slide.properties[p]) for p in slide.properties if 'mpp' in p.lower()])
            downSampleLevelsList = None
            if 0.45 <= slideMpp <= 0.55: # 20X image
                downSampleLevelsList = [1]
                print(svsFile, 'file is 20X')
            elif 0.20 <= slideMpp <= 0.30: # 40X image
                downSampleLevelsList = [2]
            else:
                sys.exit('Unsupported mpp')    

            mask,maskToClassDict=pg.MaskFromXML(annoFile,layerName,slide.dimensions,
                                                 distinguishAnnosInClass=distinguishAnnosInClass,
                                                 downSampleFactor=maskDsf)
            
            patchData,patchClasses,patchCenters=pg.PatchesFromMask(slide,mask,
                                                            downSampleLevelsList,patchSizeList,
                                                            maskToClassDict,
                                                            maxPatchesPerAnno=maxPatchesPerAnno,
                                                            showProgress=showProgress,
                                                            maxAvgPatchOverlap=maxAvgPatchOverlap,
                                                            minFracPatchInAnno=minFracPatchInAnno)
            
            pg.SaveHdf5Data(hdf5File,patchData,patchClasses,patchCenters,downSampleLevelsList,patchSizeList,svsFile)
            print(hdf5File, ' done !')
        else:
            print(hdf5File,'Already Exists!')

#%%
# patch generation code here for the remaining slides where masks were generated by a region classifier

def GeneratePatchesFromCleanMasks(maskFiles,svsFileList,sampleNumber,patchSize, yamlData):

    patchSaveDir=yamlData['patchSaveDir']
    if yamlData['dataType'] in ['IMM150','IMM150_B2']:
        hdf5patchDataFile = os.path.join(patchSaveDir, svsFileList[sampleNumber].rsplit('/',1)[1].replace('.ndpi','.hdf5'))
    else:
        hdf5patchDataFile = os.path.join(patchSaveDir, svsFileList[sampleNumber].rsplit('/',1)[1].replace('.svs','.hdf5'))
        
    slide = oSlide.open_slide(svsFileList[sampleNumber])
    
    # determine if the slide is 20X or 40X and the downSampleLevelsList 
    slideMpp = np.mean([float(slide.properties[p]) for p in slide.properties if 'mpp' in p.lower()])
    downSampleLevelsList = None
    
    if 0.45 <= slideMpp <= 0.55: # 20X image
        
        downSampleLevelsList = [1]

    elif 0.20 <= slideMpp <= 0.30: # 40X image
        
        downSampleLevelsList = [2]
    else:
        sys.exit('Unsupported mpp')
    
    with open(maskFiles[sampleNumber],'rb') as handle:
      maskData=pickle.load(handle)

    mask=maskData[0]
    maskToClassDict={1:'tissue'}

    patchSizeList=[patchSize]
    showProgress=False
    maxPatchesPerAnno=1500 # Maximum number of patches sampled from an annotation
    maxAvgPatchOverlap=8.0 # How tightly patches are allowed to overlap. 0 implies no overlap, 1 implies number of patches is selected so that combined area of patches= area of annotation
    minFracPatchInAnno=0.9 # What percentage of the patch must belong to same class as the center pixel, for the patch to be considered
    
    if not os.path.exists(hdf5patchDataFile):
        patchData, patchClasses, patchCenters = pg.PatchesFromMask( 
            slide = slide,
            mask = mask,
            downSampleFactors = downSampleLevelsList,
            patchSizes = patchSizeList,
            maskToClassDict = maskToClassDict,
            maxPatchesPerAnno = maxPatchesPerAnno,
            maxAvgPatchOverlap = maxAvgPatchOverlap,
            minFracPatchInAnno = minFracPatchInAnno,
            showProgress = showProgress)
    
        pg.SaveHdf5Data(
            hdf5Filename = hdf5patchDataFile, 
            patchData = patchData, 
            patchClasses = patchClasses, 
            patchCenters = patchCenters, 
            downSampleList = downSampleLevelsList, 
            patchSizeList = patchSizeList, 
            analyzedFile = svsFileList[sampleNumber])
        print(hdf5patchDataFile,' done!')
    else:
        print(hdf5patchDataFile,'Already Exists!')
#%%
# patchGeneration .
annoList,annoSvsList,tumorSvsList,tumorMaskList=get_file_list(yamlData)

# %% Confirm only Tumor is annotated (ie binary)
annoNameList=[]
for f in annoList:
    pos,annoNames,annoInfo,isNeg=iu.GetQPathTextAnno(f)
    #print(f, annoNames)
    annoNameList+=annoNames
    if '-Tumor' in annoNameList:
        print (f)
uniqueNames=np.unique(annoNameList)
assert len(uniqueNames)==1 and annoNames[0]=='+Tumor'

#%%
patchSize=yamlData['patchSize']
#%%
if len(annoList) > 0:
    GeneratePatchesFromAnnotations(annoList,annoSvsList,yamlData)
#%%
sampleStart=0
sampleEnd=len(tumorMaskList)

print ('Starting Pool')  
pool = mp.Pool(mp.cpu_count())
for sampleNumber in np.arange(sampleStart,sampleEnd):
  print('Submitting sample:', sampleNumber)
  pool.apply_async(GeneratePatchesFromCleanMasks,args=(tumorMaskList,tumorSvsList,
                                                       sampleNumber,patchSize,yamlData))
pool.close()  
pool.join()






